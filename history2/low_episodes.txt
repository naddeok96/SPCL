--- Low Episodes Analysis ---

Episode 79 - Total Reward: 133.54333876784173, Length: 3
  Phase 1 (Reward: 11.12861156398681):
    State breakdown:
      easy_correct_hist: [0.1131,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1039,0.2029,
 0.1973,0.    ,0.0996,0.    ,0.0887,0.1944]
      medium_correct_hist: [0.1114,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.107 ,0.195 ,
 0.1999,0.    ,0.0928,0.    ,0.0965,0.1973]
      hard_correct_hist: [0.1093,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      hard_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1035,0.198 ,
 0.2031,0.    ,0.1012,0.    ,0.0907,0.1942]
      relative_sizes: [0.7024,0.1746,0.1231]
      extra: [0.,1.]
    Action breakdown:
      Learning Rate: 0.0010
      Mixing Ratios: [0.2745,0.    ,0.7255]
      Sample Usage Fraction: 0.6181
  Phase 2 (Reward: 11.12861156398681):
    State breakdown:
      easy_correct_hist: [0.1131,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1039,0.1028,0.2969,
 0.1   ,0.1944,0.    ,0.    ,0.    ,0.0887]
      medium_correct_hist: [0.1114,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.107 ,0.0995,0.2928,
 0.0955,0.1973,0.    ,0.    ,0.    ,0.0965]
      hard_correct_hist: [0.1093,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      hard_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1035,0.1022,0.3043,
 0.0957,0.1942,0.    ,0.    ,0.    ,0.0907]
      relative_sizes: [0.7024,0.1746,0.1231]
      extra: [0.3333,0.3819]
    Action breakdown:
      Learning Rate: 0.0010
      Mixing Ratios: [0.617 ,0.1313,0.2517]
      Sample Usage Fraction: 0.8593
  Phase 3 (Reward: 111.2861156398681):
    State breakdown:
      easy_correct_hist: [0.1131,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1039,0.2999,0.1993,0.195 ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.0887]
      medium_correct_hist: [0.1114,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.107 ,0.2915,0.1942,0.1993,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.0965]
      hard_correct_hist: [0.1093,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      hard_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1035,0.2989,0.1961,0.2015,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.0907]
      relative_sizes: [0.7024,0.1746,0.1231]
      extra: [0.6667,0.0537]
    Action breakdown:
      Learning Rate: 0.0100
      Mixing Ratios: [0.1935,0.2328,0.5737]
      Sample Usage Fraction: 0.4902

Episode 77 - Total Reward: 134.9700079306599, Length: 3
  Phase 1 (Reward: 11.247500660888326):
    State breakdown:
      easy_correct_hist: [0.1131,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [0.    ,0.    ,0.    ,0.1051,0.    ,0.1014,0.    ,0.0974,0.0995,0.    ,
 0.0965,0.1996,0.098 ,0.    ,0.    ,0.0894]
      medium_correct_hist: [0.1113,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.    ,0.    ,0.    ,0.1031,0.    ,0.1012,0.    ,0.1007,0.1004,0.    ,
 0.0988,0.1953,0.098 ,0.    ,0.    ,0.0912]
      hard_correct_hist: [0.113,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,
 0.   ,0.   ,0.   ,0.   ]
      hard_incorrect_hist: [0.    ,0.    ,0.    ,0.1058,0.    ,0.1061,0.    ,0.0997,0.0964,0.    ,
 0.0971,0.1968,0.0945,0.    ,0.    ,0.0905]
      relative_sizes: [0.411 ,0.4038,0.1851]
      extra: [0.,1.]
    Action breakdown:
      Learning Rate: 0.0010
      Mixing Ratios: [0.473 ,0.0497,0.4773]
      Sample Usage Fraction: 0.1611
  Phase 2 (Reward: 11.247500660888326):
    State breakdown:
      easy_correct_hist: [0.1131,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [0.    ,0.    ,0.    ,0.1051,0.1014,0.    ,0.    ,0.1022,0.    ,0.2943,
 0.    ,0.1945,0.    ,0.    ,0.    ,0.0894]
      medium_correct_hist: [0.1113,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.    ,0.    ,0.    ,0.1031,0.1012,0.    ,0.    ,0.0955,0.    ,0.3009,
 0.    ,0.1967,0.    ,0.    ,0.    ,0.0912]
      hard_correct_hist: [0.113,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,
 0.   ,0.   ,0.   ,0.   ]
      hard_incorrect_hist: [0.    ,0.    ,0.    ,0.1058,0.1061,0.    ,0.    ,0.0974,0.    ,0.2955,
 0.    ,0.1917,0.    ,0.    ,0.    ,0.0905]
      relative_sizes: [0.411 ,0.4038,0.1851]
      extra: [0.3333,0.8389]
    Action breakdown:
      Learning Rate: 0.0100
      Mixing Ratios: [0.6003,0.0828,0.3169]
      Sample Usage Fraction: 0.6536
  Phase 3 (Reward: 112.47500660888326):
    State breakdown:
      easy_correct_hist: [0.1131,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1051,0.0974,0.    ,0.1022,
 0.1014,0.0965,0.    ,0.0995,0.0894,0.1954]
      medium_correct_hist: [0.1113,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1031,0.0998,0.    ,0.0955,
 0.1012,0.0988,0.    ,0.1004,0.0912,0.1987]
      hard_correct_hist: [0.113,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,0.   ,
 0.   ,0.   ,0.   ,0.   ]
      hard_incorrect_hist: [0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.1058,0.0994,0.    ,0.0974,
 0.1061,0.0971,0.    ,0.0964,0.0905,0.1942]
      relative_sizes: [0.411 ,0.4038,0.1851]
      extra: [0.6667,0.2906]
    Action breakdown:
      Learning Rate: 0.0100
      Mixing Ratios: [0.1957,0.3967,0.4076]
      Sample Usage Fraction: 0.7683

Episode 15 - Total Reward: 855.1747512438773, Length: 1
  Phase 1 (Reward: 855.1747512438773):
    State breakdown:
      easy_correct_hist: [0.962 ,0.0022,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [8.0927e-03,1.8057e-02,5.4645e-03,2.2312e-03,1.1345e-03,3.9707e-04,
 2.0799e-04,7.5633e-05,1.8908e-04,0.0000e+00,0.0000e+00,0.0000e+00,
 0.0000e+00,0.0000e+00,0.0000e+00,1.8908e-05]
      medium_correct_hist: [0.7993,0.033 ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.0072,0.0939,0.0442,0.0136,0.0045,0.0021,0.0012,0.0006,0.    ,0.    ,
 0.0004,0.    ,0.    ,0.    ,0.    ,0.0002]
      hard_correct_hist: [0.5713,0.1237,0.0777,0.0301,0.0041,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      hard_incorrect_hist: [0.    ,0.002 ,0.0153,0.0695,0.0639,0.0235,0.0102,0.0036,0.0026,0.001 ,
 0.    ,0.001 ,0.    ,0.    ,0.    ,0.0005]
      relative_sizes: [0.8814,0.0859,0.0326]
      extra: [0.,1.]
    Action breakdown:
      Learning Rate: 0.0100
      Mixing Ratios: [0.0302,0.6241,0.3457]
      Sample Usage Fraction: 0.0000

Episode 13 - Total Reward: 862.4220004936325, Length: 1
  Phase 1 (Reward: 862.4220004936325):
    State breakdown:
      easy_correct_hist: [0.9641,0.0014,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      easy_incorrect_hist: [5.9628e-03,1.5998e-02,6.4695e-03,2.9619e-03,1.4030e-03,6.4305e-04,
 5.0664e-04,2.7281e-04,1.7538e-04,3.8973e-05,5.8459e-05,1.9486e-05,
 0.0000e+00,0.0000e+00,0.0000e+00,1.9486e-05]
      medium_correct_hist: [0.8152,0.05  ,0.0016,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      medium_incorrect_hist: [0.    ,0.0373,0.0439,0.0236,0.0117,0.0066,0.0025,0.0034,0.0008,0.0014,
 0.0005,0.0006,0.0003,0.0003,0.    ,0.0003]
      hard_correct_hist: [0.6677,0.1092,0.0522,0.0153,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      hard_incorrect_hist: [0.    ,0.0018,0.0228,0.0504,0.0381,0.0162,0.0118,0.0057,0.0022,0.0013,
 0.0013,0.    ,0.0013,0.0009,0.0004,0.0013]
      relative_sizes: [0.8553,0.1067,0.038 ]
      extra: [0.,1.]
    Action breakdown:
      Learning Rate: 0.0100
      Mixing Ratios: [0.1736,0.3969,0.4295]
      Sample Usage Fraction: 0.0000

Episode 23 - Total Reward: 885.214164544626, Length: 1
  Phase 1 (Reward: 885.214164544626):
    State breakdown:
      easy_correct_hist: [9.1688e-01,3.9559e-04,0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00,
 0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00,
 0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00]
      easy_incorrect_hist: [3.3010e-02,3.1163e-02,9.7578e-03,4.5712e-03,2.6812e-03,8.7908e-04,
 2.6372e-04,2.1977e-04,8.7908e-05,0.0000e+00,4.3954e-05,0.0000e+00,
 0.0000e+00,0.0000e+00,0.0000e+00,4.3954e-05]
      medium_correct_hist: [8.6695e-01,1.4413e-02,4.7724e-05,0.0000e+00,0.0000e+00,0.0000e+00,
 0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00,
 0.0000e+00,0.0000e+00,0.0000e+00,0.0000e+00]
      medium_incorrect_hist: [1.1549e-02,5.9798e-02,2.3432e-02,9.4015e-03,5.0110e-03,4.0565e-03,
 1.9089e-03,1.2408e-03,9.5447e-04,4.2951e-04,2.3862e-04,1.4317e-04,
 3.3407e-04,0.0000e+00,0.0000e+00,9.5447e-05]
      hard_correct_hist: [0.7425,0.103 ,0.0092,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,0.    ,
 0.    ,0.    ,0.    ,0.    ,0.    ,0.    ]
      hard_incorrect_hist: [0.0000e+00,4.2835e-02,5.1427e-02,2.4363e-02,1.1476e-02,6.1982e-03,
 3.9276e-03,1.7797e-03,1.2274e-03,6.7505e-04,4.9095e-04,2.4547e-04,
 3.0684e-04,1.2274e-04,6.1369e-05,1.2274e-04]
      relative_sizes: [0.3792,0.3492,0.2716]
      extra: [0.,1.]
    Action breakdown:
      Learning Rate: 0.0010
      Mixing Ratios: [0.1326,0.1343,0.7331]
      Sample Usage Fraction: 0.0000

